# Cinematic Rendering in UE4 with Real-Time Ray Tracing and Denoising
# UE4 电影级渲染：实时光线追踪与去噪

## 摘要：
我们通过在UE4中集成光线追踪技术来呈现电影级品质的实时渲。借助于整合工程技术，新的光线追踪硬件，混合渲染技术同新颖的去噪算法， 我们将前沿GPU光线追踪的性能提升了一个数量级。

## 19.1 简介：

使用光线追踪来生成图片，可以得到比光栅化技术更高的质量。 这种情况的一个表现是，近年来，大多数电影特效都使用了光线追踪技术。然而，在实时性的应用程序，比如游戏中使用光线追踪是具有挑战性的。光线追踪算法的许多步骤都是很耗费资源的, 包括包围体层次(Boulding volume hiearchy, BVH）的构建，BVH的遍历，和射线/基本几何体（primitives）的相交测试。此外，在光线追踪技术中广泛采用的随机抽样，通常需要在每个像素上进行数百到数千个采样来得到最终收敛的渲染图。 这远远超出现代实时渲染技术所能接受的计算量预算几个数量级。另外，直到最近，实时图形API还没有对于光线追踪技术的支持，使得将光线追踪整合到当前的游戏中成为一件充满挑战的任务。这个情况在2018年 DirectX 12和Vulkan宣布支持光线追踪时迎来了改变。

在本章中，我们将解决许多相关问题，并且会对已经集成在UE4中的光线追踪技术进行演示。特别地包括：
+ 我们在UE4中采用并集成了DirectX 光线追踪（DXR），这使得我们可以最大限度地重用已有的材质着色器代码。
+ 我们利用NVIDIA图灵架构中的RT Cores来实现 基于硬件加速的BVH遍历和光线/三角面片相交测试。
+ 我们发明了针对高质量随机渲染效果的新颖的重建滤波器， 渲染效果覆盖软阴影，光泽反射，漫反射， 全局光照，环境光遮挡和半透明效果，同时输入的每像素光线采样数甚至可以减少到一个。

硬件加速和软件创新的结合使我们能够创造出两个电影级品质的实时光线追踪演示 "Reflection"（Lucasfilm)和“Speed of Light” (Porsche)。


## 19.2 在UE4中集成光线追踪

在UE4这样的大型应用程序中集成光线追踪框架是一项具有挑战性的任务，可以说是自UE4 被发布以来最大的架构变化之一。在集成光线追踪到UE4时我们有如下一些目标：
+ 性能：这是UE4的一个关键方面，因此光线追踪功能应与用户期望的一致。有助于提高性能的决策之一是G-buffer仍然使用现有的基于光栅化的技术来计算。基于这样的决策，光线被追踪来计算特定的效果所涉及到的传递，例如反射或面积光阴影。
+ 兼容性：光线追踪通路的输出必须兼容现有的UE4的着色和后处理管道。
+ 着色一致性：UE4使用的着色模型必须使用光线追踪来准确实现，从而产生和现有UE4一致的着色效果。具体来说，对于UE4提供的多种着色模型在计算BRDF，重要性采样和BRDF概率分布函数的时候，我们在现有着色器代码中严格地遵循相同的机制。
+ 最大限度地减少中断：现有的UE4用户会发现，集成是很易于理解和扩展的。因此，它必须遵循UE设计范式。
+ 多平台支持：虽然最初UE4中的实时光线追踪是完全基于DXR的，UE4的多平台本质需要我们在设计新系统的同时，尽可能确保最终将其移植到其他未来解决方案时不需要做大的重构。

整个集成的过程分为两个阶段。第一个是原型设计阶段，在这里我们与ILMxLAB合作制作出了“反射”（Reflection, 一部Lucasfilm星球大战短片）和“光速”（保时捷）的演示短片，目标在于探索未来在UE中集成光线追踪技术的理想方法，同时期望可以做到有效扩展。这有助于我们对集成中最具挑战性的如下方面进行总结: 性能，API，集成延迟着色管道(Deferred shading pipeline)，渲染硬件接口（RHI）中所需的变更，用于将用户从每个硬件平台的细节中隔离出来的一层抽象，着色器API的变化，可伸缩性等。
当找到第一阶段出现大多数问题的答案后，我们之后进行到第二阶段。第二阶段包括对UE4高层渲染系统的主要改写，这除了会提供更好的实时光线追踪集成外，还带来了包括显著提升整体性能等其他优势。

### 19.2.1  第一阶段:实验集成
在较高的层次上，将光线追踪集成到基于光栅化的实时渲染引擎中的过程包含以下几个步骤：
+ 对将被光线追踪的几何体进行注册，从而在有变更时可以构建或更新加速结构。
+ 创建命中着色器，以便在任何时候当光线打到一个集合体时，我们可以像在基于光栅化的渲染中一样计算它的材质参数。
+ 创建光线生成着色器以供追踪各种场景案例中的光线，如阴影或反射。

#### 19.2.1.1　加速结构的DIRECTX 光线追踪背景
要理解第一步，首先要了解 DirectX光线追踪API中所公开的两级加速结构（AS）。在DXR中，有两种类型的加速结构，组合形成两级结构：顶层加速结构（TLAS）和底层加速结构（BLAS）。这些如图19-1所示。 TLAS构建在一组实例上，每个实例都有自己的变换矩阵和指向BLAS的指针。每个BLAS都构建在一组几何元上，这些几何元可以是三角形或AABB，其中AABB用于包围自定义几何体，这些几何体将在沿着光线找到AABB时所进行的加速结构遍历期间，用于使用自定义交点着色器进行求交。对于动态场景，TLAS通常会在每帧重建。每个BLAS为每个独特的几何体至少构建一次。如果几何是静态的，则在初始构建之后不需要额外的BLAS构建操作。对于动态几何体，BLAS则需要更新或完全重建。当输入图元的数量改变时（即，当需要添加或移除三角形或AABB时，比如对于动态曲面细分或其他程序几何生成方法，例如粒子系统），需要完整的BLAS重建。在使用BVH（这是NVIDIA RTX实现使用的）的情况下，BLAS更新需要重新操作，其中结构树的所有AABB都从叶子更新到根，但树结构保持不变。

![Figure 19-1][id]

#### 19.2.1.2 对UE4 RHI的实验扩展
在实验性的UE4实现中，受NVIDIA OptiX API启发，我们利用抽象扩展了渲染硬件接口（RHI），但比Optix API略有简化。抽象由三种对象类型组成：rtScene，rtObject和rtGeometry。 rtScene由rtObjects组成，它们实际上是实例，每个都指向一个rtGeometry。 rtScene封装TLAS，同时rtGeometry封装BLAS。 rtGeometry和指向给定rtGeometry的任何rtObject都可以由多个部分组成，所有部分属于同一个UE4primitive对象（静态Mesh或骨架Mesh），因此共享相同的索引和顶点缓冲区但可能使用不同的（材质）命中着色器。 rtGeometry本身没有与之关联的命中着色器。我们在rtObject部分设置了命中着色器及其参数。

我们也对引擎材质着色器系统和RHI进行了扩展，以支持DXR中的新光线追踪着色器类型：光线生成，最近命中，任意命中，交叉点和未命中。具有这些着色器阶段的光线追踪管道如图19-2所示。 除了最近命中t和任意命中着色器之外，我们还扩展了引擎以支持在原处使用现有的顶点着色器（VS）和像素着色器（PS）。我们利用对开源Microsoft DirectX编译器进行扩展的实用程序，提供了一种机制，可以从VS和PS的预编译DXIL表示生成最近命中和任意命中着色器。该实用程序将VS代码，输入汇编阶段的输入布局（包括顶点和索引缓冲区格式和步幅）以及PS代码作为输入。给定此输入，它可以生成执行索引缓冲区提取，顶点属性提取，格式转换和VS评估（对于三角形中的三个顶点中的每一个）的最优代码，然后使用命中处的重心坐标对VS输出进行插值，其结果被提供作为PS的输入。该实用程序还能够生成最小的任意命中着色器以执行alpha测试。这允许引擎中的渲染代码继续使用顶点和像素着色器，就好像它们将用于栅格化G缓冲区一样，依旧设置着色器参数。

![Figure 19-2][id]

在这个实验性RHI抽象下的实现还有两个额外的职责：编译光线跟踪着色器（到适应于GPU的特定表示）和管理着色器绑定表，这个表指向需要用于每个几何体的着色器代码和着色器参数。


##### 有效地编译光线跟踪着色器
在引入RTX和DirectX光线跟踪之前，图形API中的现有管道抽象（用于光栅化和计算）仅需要提供少量着色器（1到5个）来创建所谓的管道状态对象（PSO），它封装了输入着色器的已编译的对应机器特定代码。这些图形API允许在需要时并行创建许多这些管道状态对象，每个对象用于不同的材质或渲染通道。然而，光线跟踪管道以显着的方式改变了这一点。必须使用所有可能会在给定场景中执行的着色器，才能创建光线跟踪管道状态对象（RTPSO），这样当光线到达任何对象时，无论代码是什么系统都可以执行与其关联的着色器代码。在当今游戏的复杂内容中，这很容易意味着成千上万的着色器。如果按顺序执行，将数千个光线跟踪着色器编译到一个RTPSO的机器代码中可能非常耗时。幸运的是，DirectX Raytracing和RTX启用的所有其他NVIDIA光线跟踪API都能够将多个光线跟踪着色器并行编译为机器代码。这种并行编译可以利用当今CPU的多核。在实验性UE4实现中，我们通过简单地调度单独的任务来使用此功能，每个任务将单个光线跟踪着色器或命中组编译成DXR调用集合的内容。对于每一帧，如果没有其他着色器编译任务已经在执行，我们会检查是否需要任何新的着色器并且尚不可用。如果找到任何这样的着色器，我们就启动一批新的着色器编译任务。同时，我们还检查了每一帧是否已完成任何先前的着色器编译任务。如果是这样的话，我们会创建一个新的RTPSO，取代之前的RTPSO。在任何时候，单个RTPSO用于帧中的所有DispatchRays() 调用。任何由新的RTPSO替换的旧RTPSO被安排在任何在执行(in-flight) 帧不再使用时延迟删除。在构建TLAS时，当前RTPSO中尚未提供所需着色器的对象将会被删除（跳过）。

**着色器绑定表** 此表是由多个记录组成的内存缓冲区，每个记录包含一个不透明着色器标识符和一些着色器参数，这些参数等同于DirectX 12调用根表（用于图形管道绘制或计算管道调度）。由于以上第一个实验实现旨在更新每帧中场景中每个对象的着色器参数，因此着色器绑定表管理比较简单，只是模仿命令缓冲区。着色器绑定表被分配为N个缓冲线性内存缓冲区，其大小由场景中对象的数量决定。在每一帧我们都开始在GPU可见的GPU可写缓冲区（在上传堆中）中从头开始编写整个着色器绑定表。然后，我们将GPU副本从此缓冲区加入到GPU本地的对应项的队列中。基于围栅的同步用来防止覆盖先前使用N帧的着色器绑定表的CPU或GPU副本。

#### 19.2.1.3 为各种引擎primitives登记几何
要为加速结构构造注册几何，我们必须确保UE4中的各种基元（primitives）具有为它们创建的RHI级rtGeometry和rtObject。通常，这需要确定应该创建rtGeometry和rtObjects的正确范围。对于大多数基元，可以在与顶点和索引缓冲区几何体相同的范围内创建rtGeometry。对于静态三角网格，这很简单，但对于其他基元，它可以更多地参与其中。例如，粒子系统，风景（地形）基元和骨架网格物体(Skeloton Meshes)（即，蒙皮几何体，可能使用变形目标或布料模拟.）需要特殊处理。在UE4中，我们利用了现有的GPUSkinCache，这是一个基于计算着色器的系统，可以在每个帧上执行换肤，进入临时GPU缓冲区，可用作光栅化通道，加速结构更新和命中着色器的输入。值得注意的是，每个Skeletal Mesh实例都需要自己独立的BLAS;因此，在这种情况下，骨架网格物体的每个实例都需要单独的rtGeometry，并且不存在实例化或共享这些实例，如静态网格物体的情况。我们还尝试了对其他类型的动态几何体的支持，例如级联粒子系统和景观（地形）系统。粒子系统可以使用粒子网格，其中每个粒子成为指向静态网格物体rtGeometry的实例，或程序生成的三角形几何体，例如精灵或丝带。由于时间有限，这种实验支持仅限于CPU模拟的粒子系统。对于景观系统，我们对地形斑块，树叶几何体和样条线网格物体（它们是通过沿B样条曲线插值三角形网格生成的网格物体）进行了一些实验支持。对于其中一些，我们依赖于生成顶点几何的现有CPU代码。

#### 19.2.1.4 更新场景的光线追踪表示
在每一帧，UE4渲染器执行其渲染循环体，在其中执行多次光线传递，例如光栅化G缓冲区，应用直接照明或后处理。我们修改了这个循环来更新用于光线跟踪的场景表示，它的最低层由着色器绑定表，相关的内存缓冲区和资源描述符以及加速结构组成。

从高层渲染器的角度来看，第一步涉及确保场景中所有对象的着色器参数是最新的。为此，我们利用现有的Base Pass渲染逻辑，这个通常是被用于在延迟着色渲染器中栅格化G缓冲区。这两者的主要区别在于，对于光线跟踪，我们必须在场景中的所有对象上执行此循环，而不仅是基于遮挡剔除结果同时在在相机平截头体内并且可能可见的。第二个区别在于，第一个实现使用前向着色渲染器中的VS和PS， 而不是使用延迟着色G缓冲区渲染中的VS和PS，因为当着色点击反射时，这看起来很自然。第三个区别是我们实际上必须更新多种光线类型的着色器参数，并且在某些情况下使用稍微不同的着色器。

#### 19.2.1.5 迭代所有对象
在大型场景中，可能会花费大量的CPU时间来更新所有对象的着色器参数。我们认为这是一个潜在的问题，并对此得出结论，即我们应该把传统上称为保留模式渲染作为目标来避免这个问题。与立即模式的渲染不同，在每个帧中，CPU重新提交许多相同的命令，一个接一个地绘制相同的对象，在保留模式下渲染每帧执行的工作只是更新自上一帧以来已更改的任何内容。保留模式渲染更适合光线追踪，因为与光栅化不同，在光线追踪中，我们需要有关整个场景的全局信息。 因此，NVIDIA RTX支持的所有GPU光线追踪API（OptiX，DirectX光线追踪和Vulkan光线追踪）都支持保留模式渲染。然而，今天的大多数实时渲染引擎仍然是围绕自OpenGL以来过去二十年使用的光栅化API的限制而设计的。因此，渲染器被编写为在每一帧重新执行所有着色器参数设置和绘图代码，尽可能少地根据需要只渲染摄像机可见的对象。虽然这种方法适用于我们用于演示实时光线追踪的小场景，但我们知道它无法扩展到大的场景世界。出于这个原因，UE4渲染团队开始了一个项目来改造高级渲染器，以实现更有效的保留模式渲染方法。


#### 19.2.1.6 为光线追踪渲染定制阴影
 光线追踪和光栅化渲染之间的第二个区别是我们必须从VS和PS代码构建命中着色器，小程度上这些着色器是为光线追踪而定制的。最初的方法基于用于UE4中的前向着色的代码，除了依赖于与屏幕空间缓冲区相关的信息的逻辑被省略了。 （旁注：这意味着使用访问屏幕空间缓冲区的节点的材料在光线追踪时无法正常工作。结合光栅化和​​光线追踪时应避免使用这些材料。）虽然我们的初始实现使用基于UE4的命中着色器前向渲染着色器，随着时间的推移，我们重构着色器代码，使得命中着色器看起来更接近用于延迟着色中的G缓冲区渲染的着色器。在这种新模式下，所有动态光照都在光线生成着色器中执行，而不是在命中着色器中执行。这减少了命中着色器的大小和复杂性，避免了在命中着色器中执行嵌套的TraceRay() 调用，并允许我们修改光线追踪着色的光照代码，并且迭代次数大大减少，这要归功于无需等待重建数千个素材像素着色器。除了这一变化之外，我们还通过确保在命中处(origin + t * direction)使用从射线信息计算的位置来优化VS代码，从而避免与VS中的位置相关的存储器负载和计算。此外，在可能的情况下，我们将计算从VS移动到PS，例如在计算变换的法线和切线时。总的来说，这将VS代码简化为主要包含数据获取和格式转换。
 
#### 19.2.1.7 多个射线类型的阴影参数的批量提交
第三个区别是更新多种光线类型的参数，这意味着在某些情况下，如果其中一种光线类型需要一组完全独立的VS和PS，我们必须多次遍历场景中的所有对象。 但在某些情况下，我们能够显着降低其他光线类型的开销。 例如，当这些光线类型可以使用具有兼容的着色器参数的命中着色器时，通过允许RHI抽象同时为多种光线类型提交着色器参数，我们能够处理两种最常见光线类型（材质评估和任何命中阴影）的更新。 这个要求由DirectX编译器实用程序保证，它将VS和PS对转换为命中着色器，因为它确保最近命中着色器和任意命中着色器的VS和PS参数布局相同（因为两者都是从相同的VS和PS对）。鉴于此以及Any Hit Shadow光线类型仅使用与材质评估光线类型相结合的任意命中着色器以及无效最近命中着色器这一事实，对两条光线类型使用相同的着色器绑定表记录数据是较为简单的， 不过要具有不同的着色器标识符。

#### 19.2.1.8 更新实体变换
在填充着色器绑定表记录的过程中，我们还负责在相关的rtObject中记录它们的偏移量。 此信息将被提供给TLAS构建操作，因为DXR实现会使用它来决定要执行的命中着色器以及使用什么参数。 除了更新所有着色器参数之外，我们还必须更新与每个rtObject相关联的实例变换和标志。 在更新着色器参数之前，这是在单独的循环中完成的。在诸多性质中，实例级的标志允许控制masking和背面剔除逻辑等。 在UE4中使用屏蔽位（masking bit）来实现对照明通道的支持，这允许艺术家限制特定的灯组来与特定的对象组进行交互。背面剔除位（bit）用于确保光栅化和光线追踪结果在视觉上匹配（剔除对于光线追踪的性能优化，不同于对于光栅追踪化的性能优化）。

#### 19.2.1.9 构建加速结构
在更新所有光线追踪着色器参数，rtObject变换以及剔除和屏蔽位后，包含命中着色器的着色器绑定表已准备就绪，并且所有rtObject都知道其对应的着色器绑定表记录。此时，我们将进入下一步，即调度任何底层加速结构的构建或更新，以及TLAS的重建。在实验实现中，该步骤还处理与加速结构相关联的存储器的延迟分配。此阶段的一个重要优化是确保在BLAS更新之后所需的任何资源转换障碍被推迟在TLAS构建之前执行，而不是在每次BLAS更新之后立即执行。延迟很重要，因为这些转换障碍中的每一个都是GPU上的同步步骤。将转换合并到命令缓冲区中的单个点可避免冗余同步，否则会导致GPU频繁变为空闲。通过合并转换，我们在所有BLAS更新之后执行此同步一次，并允许多个BLAS更新（可能对于许多小三角形网格）在GPU上运行时重叠。


#### 19.2.1.10 未命中着色器
我们未命中着色器的使用是有限的。尽管在RHI级别暴露了未命中着色器，但我们从未在RHI的引擎端使用过它们，我们依赖于RHI实现预先初始化一组相同的默认未命中着色器（每个光线类型一个），它只是在payload中初始化一个HitT值为一个特定的负值，以此来指示光线没有击中任何东西。


### 19.2.2 第二阶段
在通过创建两个high-level光线追踪演示短片期间积累了经验之后，我们可以进行大规模重构，从而可以把针对于项目的代码转换为适合扩展到所有UE4用户需求的代码。 此阶段的最终目标之一是将UE4渲染系统从立即模式(immediate mode)移动到保留模式(retained model)。这会带来更高的效率，因为只有在给定帧处改变的对象才被有效地更新。 由于光栅化管道的限制，UE4最初是按照立即模式样式编写的。然而，这对于光线追踪大场景来说是一个严重的限制，因为它会在每帧更新所有对象，即使大多数时间只有一小部分发生了变化。 因此，转向保留模式是此阶段的关键成就之一。

我们的最终目标是在未来可以将光线追踪集成到任何平台中，所以我们将需求划分为不同的层次，以了解支持每个功能所需的内容以及我们如何面对任何特定设备的限制同时对于更先进的硬件也不牺牲其功能。


#### 19.2.2.1 需求层次一
层次一描述了集成基本光线追踪功能所需的最低功能级别，如现有的光线追踪API，如Radeon Rays或Metal Performance Shaders。输入是包含光线信息（原点，方向）的缓冲区，着色器输出是包含交叉点结果的缓冲区。此层中没有内置的TraceRay内部函数，也没有任何命中着色器。 第一层非常适合实现简单的光线追踪效果，例如不透明阴影或环境光遮蔽，但超出这些要求具有挑战性，并且需要在代码中进行复杂的更改，这会造成限制并使其难以实现良好的执行效率。

#### 19.2.2.2  需求层次二
第二层支持光线生成着色器，它可以调用TraceRay内部函数，其输出在追踪调用后立即可用。此级别的功能还支持动态着色器调度，使用RTPSO和着色器绑定表抽象。 第二层不支持递归光线追踪，因此无法从命中着色器生成新光线。在第一阶段中，我们发现这在实践中并不是一个很大的限制，同时它具有减少命中着色器的大小和复杂性的积极副作用。

第二层使得在UE4的光线追踪集成中定义的大部分目标的实现成为可能。 因此，有了第二层功能，可以认为UE4射线追踪流水线的设计已经完成。

#### 19.2.2.3  需求层次三
第三层紧跟DXR规范。它支持所有第二层功能和具有预定义最大深度的递归调用。它还支持追踪光线生成着色器之外的其他着色器类型的光线，以及高级功能，例如可自定义的加速结构遍历。第三层是迄今为止最强大的功能集，它能够以模块化方式集成离线渲染中的高级光线追踪功能（例如光子映射和辐照度缓存）。在硬件支持的情况下，UE4中的光线追踪集成设计可以利用第3层功能。


## 19.3 实时光线追踪和去噪
 除了从UE4中的光线追踪集成中汲取的经验教训之外，初始实验阶段对于探索实时光线追踪的可能性至关重要。我们从镜面反射和硬阴影开始，继续通过添加去噪来从有限的光线采样预算中近似光泽反射和区域光阴影，然后添加环境遮挡，漫反射全局照明和半透明。 

 我们注意到基于光栅化的渲染器（包括离线和实时）通常将渲染方程分成多个光路的分组并单独处理每个分组。 例如，为屏幕空间反射执行单独的传递(pass)，为直接照明执行另一次传递（pass）。这在光线追踪渲染器中较少使用，特别是通过累积数十，数百或数千个光路来渲染的离线路径追踪器(path tracers)。

 一些光线追踪渲染器使用技术来提升收敛或交互性/实时性，例如，虚拟点光源（VPL, 即时光能传递[6] instant radiosity），路径空间滤波[1]以及很多去噪算法。有关蒙特卡罗渲染的最新去噪技术的概述，请参阅Zwicker等优秀的最新报告[14]。 Zimmer et al.[13]将整个光线树分割成单独的缓冲区，并在合成最终图片之前对每个缓冲区单独应用去噪滤波器。 在我们的场景中，我们遵循类似的方法，分割出我们解决渲染方程时出现的光路。我们对来自不同光线类型的结果应用自定义滤波器，例如阴影，反射和漫射光线。我们对每个效果只在每个像素使用很少的光线采样然后进行比较激进地去噪以弥补采样的不足。我们利用局部属性来提高去噪的质量（例如光的大小或有光泽的BRDF波瓣的形状），并将结果组合起来生成接近离线渲染器生成的图像。我们将此技术称为分区光路滤波。



### 19.3.1 光线追踪阴影
 光线追踪阴影相比于阴影贴图的一个显着优点是，即使对于具有大面积的光源，光线追踪也可以轻松模拟物理性质上精确的半影，从而提高渲染图像的视觉真实感。 使用比较大的半影(penumbra)来生成高质量的软阴影是我们的目标之一。在“Reflections”（Lucasfilm）演示中，区域灯光(area light) 和软阴影(soft shadows) 是两个最重要的视觉组成。 示例请参见图19-3。

![Figure 19-3][id]
Figure 19-3 的caption：
（a）原“反射”（Lucasfilm）演示中的渲染效果，包含光线追踪产生的软阴影。注意两个冲锋队员头盔下的软阴影。 （b）去掉软阴影的效果，照明会失去区域光照下的保真度，并且图像不那么逼真。 


“光速”（保时捷）演示中也显示了类似的效果，可见保时捷911 Speedster车上的巨大区域灯光投射出阴影。大型漫射灯通常用于汽车展览，它们产生具有较大半影的漫反射阴影。来自大面积光源的精确阴影半影对于诸如阴影贴图的传统基于光栅化的技术而言具有挑战性。通过光线追踪，我们可以准确地模拟这种现象，如图19-4所示。
 ![Figure 19-4][id]
 
 
### 19.3.1.1 光照估计

我们的演示中的区域光的光照估计是使用线性变换余弦（LTC）方法[2]计算的，该方法提供了无差异的光照估计（不包括可见性）。为了渲染区域光源的阴影，在将高级图像重建算法应用于结果之前，我们使用光线追踪来收集可见性(visibility)的噪声估计。 最后，我们在照明结果的基础上合成了被去噪的visibility项。
在数学上，这可以写为渲染方程[4]的拆分和近似（见下）:

> **Equation (1)**

这里，L(ωo)是从方向ωo离开表面的辐射亮度(radiance); V(ωi) 是方向ωi上的二元可见项(visibility);表面特性f是BRDF（双向反射分布函数）; Li(ωi) 是沿ωi方向的入射光; 表面法线与入射光方向之间的角度为θi，|cosθi|表示由于该角度引起的几何衰减。对于漫反射曲面，此近似具有可忽略的偏差，通常用于阴影映射技术。 对于在光泽表面上具有遮挡的区域光着色，可以使用来自Heitz等人[3]的比率估计器以获得更准确的结果。 相反地，我们直接使用光线追踪反射和去噪来处理镜面区域的阴影，并在“光速”（保时捷）演示中使用遮挡信息。更多详细信息，请参见第19.3.2.3节。
 
 
#### 19.3.1.2 阴影去噪
为了获得具有大半影的高质量光线追踪区域光的阴影，通常每个像素需要数百个可见性样本来做估计，从而确保没有明显的噪声。 所需的光线数量取决于光源的大小以及场景中遮挡物的位置和大小。

对于实时渲染，我们有更严格的光线预算，数百条光线远远超出了我们的性能预算。 对于“反射”（Lucasfilm）和“光速”（保时捷）演示，我们对于每个光源每像素仅仅使用一个样本。如此少的样本会导致结果包含大量噪音。我们应用了一种先进的去噪滤波器来重建一个接近渲染真实效果(ground truth)的无噪声图像。

我们设计了一种专用用于半影区域光影的去噪算法。 阴影降噪器分为空间和时间分量。空间分量的灵感来自最近基于局部遮挡的频率分析有效滤波器的工作，例如，用于软阴影的轴对齐滤波[8]和Yan等人的剪切滤波器[12]。 降噪器已知有关光源的信息，例如它的大小，形状和方向，它与接收器的距离，以及阴影光线的命中距离。 降噪器使用此信息来尝试对每个像素得出最佳的空间滤波器覆盖区(footprint)。footprint是各向异性的，每个像素的方向不同。
图19-5显示了各向异性空间核的近似可视化。 内核形状沿着半影的方向延伸，在去噪后产生高质量的图像。我们的降噪器的时序成分将每个像素的有效样本数增加到8-16左右。如果启用时序滤波器，则需要注意时间滞后，但我们按照Salvi [10]的建议执行时间钳制以减少滞后。 

![Figure 19-5][id]

鉴于降噪器使用每个光源的信息，我们必须分别对每个光源投射的阴影进行单独去噪。我们的去噪成本与场景中的光源数量成线性关系。然而，去噪效果的质量高于我们尝试对多个灯使用通用滤波器的质量，因此我们为这些演示选择了每个灯的滤波器。  图19-6中的输入图像使用每个像素的一条阴影光线进行渲染，以模拟汽车顶部巨大的矩形光源投射的柔和照明。在这样的采样率下，产生的图像具有非常多噪点。我们的空间降噪器消除了大部分噪音，但仍然存在一些伪影(artifacts)。结合时序和空间去噪分量，结果接近于每像素2048条光线采样渲染出的的真实图像。

![Figure 19-6][id]

对于中等大小的光源，我们的空间降噪器可以产生高质量的结果。 在“反射”（Lucasfilm）演示中，单独的空间去噪就足以产生阴影质量结果，对此我们的艺术家感到很高兴。对于我们在“光速”（保时捷）演示中使用的巨型光源类型，纯空间去噪效果不符合我们的质量标准。 因此，我们还使用时间分量来为我们的“光速”（保时捷）演示进行去噪，以轻微的时间滞后为代价提高了重建质量。

### 19.3.2光线追踪反射
 真实的反射是基于光线追踪渲染的另一个关键效果。当前基于光栅化的技术（例如屏幕空间反射（SSR）[11]）经常会带来屏幕外内容中的伪像。其他技术，如预先集成的光探测器[5]，都无法很好地适应动态场景，并且无法准确模拟光泽反射中存在的所有特征，例如沿表面法线方向拉伸和接触硬化(contact hardening)。此外，光线追踪可以说是处理任意形状表面上多次反射的最有效方法。

 图19-7展示了我们能够在“Reflections”（Lucasfilm）演示中使用光线追踪反射产生的渲染效果。请注意Phasma装甲部分之间光线多次反弹的互相反射。
 
 ![Figure 19-7][id]
 

#### 19.3.2.1简化的反射阴影
虽然光线追踪使得支持任意曲面上的动态反射变得更加容易，即使对于屏幕外内容，在反射中光线反弹的命中点处计算阴影和着色也是昂贵的。为了降低反射命中点的材质计算成本，我们提供如下选项： 可以使用不同的被艺术家简化过的材质进行光线追踪反射着色。这种材质简化对最终感知质量几乎没有影响，因为反射物体通常在凸面反射器上通常被最小化，并且去除材料中的微细节通常在视觉上不明显，但对性能大有裨益。 图19-8将主视图（左）中具有多个纹理贴图带来的丰富微细节的常规复杂材质与和 右图中 反射命中着色中使用的简化版本进行了比较。

 ![Figure 19-8][id]


#### 19.3.2.2对于光泽反射的去噪
使用光线追踪获得完美平滑的镜面反射效果很好，但在现实世界中，大多数镜面表面都不像镜子一样。 它们通常在其表面上具有不同程度的粗糙度和凹凸感。 通过光线追踪，通常可以随机地对材料的局部BRDF进行数百至数千个采样，具体取决于粗糙度和入射辐射。 这样做对于实时渲染是不切实际的。

我们实现了自适应多次反弹机制来驱动反射光线的产生。反射光线的发射受到命中表面粗糙度的控制，因此命中具有较高粗糙度的几何形状的光线会较早地被杀掉。平均而言，我们仅为每个像素提供两条反射光线，用于两次反射bounce，因此对于每个可见的着色点，我们只有一个BRDF样本。结果具有非常多噪点，我们再次应用复杂的去噪滤波器来重建接近真实的光泽反射。

我们设计了一种仅适用于反射的入射辐射量的去噪算法。光泽反射是在着色点周围半球上的入射辐射量L和BRDF f的乘积的积分。

我们将乘积的积分分成两个积分的近似乘积，

> ** Equation 2**

这样就简化了去噪任务。 我们仅对入射辐射量∫L(ωi)dωi进行去噪。 BRDF积分可以分离出来并预先集成。 这是预先集成的光探针(light probe)的常见近似[5]。此外，镜面反照的albedo (specular albedo) 也包含在BRDF中，因此通过仅过滤辐射项，我们不需要担心纹理细节的过度模糊。

滤波器堆栈具有时间和空间分量。对于空间分量，我们在屏幕空间中导出一个各向异性形状的核，该核遵照局部着色点处的BRDF分布。通过基于命中距离，表面粗糙度和法线将BRDF波瓣投射回屏幕空间来对核进行估计。生成的核在每个像素具有不同的核大小和方向。如图19-9所示。
 
 ![Figure 19-9][id]


我们基于BRDF的滤波核的另一个值得注意的特性是它可以通过过滤镜面表面过滤产生适度粗糙的光泽表面，如图19-10,19-11和19-12 所示。 我们的滤波器对于1个spp的输入可以产生不错的结果，同使用16384 spp渲染得到的真实结果非常相近。请参考图19-11和图12中的示例。

 ![Figure 19-10][id]
 ![Figure 19-11][id]
 ![Figure 19-12][id]

该空间滤波器可以真实地重建具有中等粗糙度的光泽表面（GGX平方粗糙度小于约0.25）。对于更高的粗糙度值，我们应用像Stachowiak等人[11]的有偏的随机BRDF采样，并将将时间分量与空间分量相结合，以获得更好的去噪质量。 

反射表面上的时间重投影需要反射物体的运动矢量，这可能难以获得。 以前，Stachowiak et al.[11] 使用反射的虚拟深度来重建由平面反射器(reflector)内的反射物体的相机移动引起的运动矢量。 然而，对于弯曲的反射器，这种方法不能很好地工作。在第32章，Hirvonen et al.介绍了一种新方法，将每个局部像素邻域建模为薄透镜，然后使用薄透镜方程导出反射物体的运动矢量。这个方法适用于曲面反射器，并且我们使用这种方法计算时间滤波器中的运动矢量。



#### 19.3.2.3 光线追踪反射的镜面反射着色 (specular shading)
 线性变换余弦（LTC）[2]是一种可以分析性地为任意粗糙度产生逼真的区域光着色的技术，但需要注意的是它不能处理遮挡。由于我们的反射解决方案会对于每像素一个样本产生很好的光泽反射，我们可以使用它直接估计区域光源下材质着色中的镜面反射分量。作为LTC的代替，我们简单地将区域光源视为发光物体，在反射命中点处对它们进行着色，然后应用我们的去噪滤波器来重建包括遮挡信息的镜面反射着色。图19-13显示了这两种方法的比较。

 ![Figure 19-13][id]


 ### 19.3.3 光线追踪漫反射全局光照

 为了追求照片级真实感，在“反射”（Lucasfilm）和“光速”（保时捷）的演示中，我们使用光线追踪来计算间接光以增加渲染图片的真实感。 我们用于两个演示的技术略有不同。对于“反射”（Lucasfilm），我们使用光线追踪从预先计算的体积光照贴图中获取辐照度信息，以计算动态角色的间接光。对于“光速”（保时捷）演示，我们使用了一种更brute-force的方法直接进行路径追踪，其间利用来自G缓冲器的间接漫反射光线的两次碰撞。我们使用下一事件估计的方法(next event estimation) 来加速收敛。
 
 #### 19.3.3.1 环境光遮蔽

环境遮挡提供了符合物理性质和艺术家可控制的全局照明的一个近似实现。将光线与遮挡区分开会破坏物理正确性，但可以带来更高的效率。我们应用环境光遮蔽的技术同已在电影中使用了数十年的直接的、完备记载的算法相同。 我们以一个余弦半球分布发射几条光线，以候选点的阴影法线为中心。 因此我们得以生成一个屏幕空间遮挡遮罩，可以全局性地减弱照明贡献。

虽然虚幻引擎(Unreal Engine) 支持屏幕空间环境光遮挡（SSAO），但我们在演示中避免使用它。 SSAO存在明显的缺点。它对视锥体的依赖性导致边界处的渐晕，并且不能准确地捕获主要平行于观察方向的薄遮挡物。此外，视锥体外的遮挡物不会对SSAO的测量做出贡献。对于像我们的演示之类的动画，艺术家通常会完全避免这种情况，或者抑制较大光线距离的影响。然而通过使用DXR，我们可以捕获独立于视锥体方向的遮挡。

#### 19.3.3.2 从光照贴图(Light Map)中得到间接漫反射
对于“反射”（Lucasfilm），我们需要一种能够提供有效色彩混合的环境光遮蔽技术。 虽然我们重视环境光遮蔽的效率，但它带来的全局变暗效果对我们的艺术家来说是不可取的。我们实现了间接漫反射通路(pass)作为参考比较。对于该算法，以与传统环境光遮蔽类似的方式，我们从候选G缓冲样本投射余弦半球分布的光线。如果我们的可见性探测光线击中发光体，我们不是记录命中率，而是记录BRDF的加权结果。正如预期，得到有意义结果所需要的光线数量是难以估计的，但它们为更近似的技术提供了基线。 

我们使用虚幻引擎(Unreal Engine)的光照映射解决方案来提供近似的间接贡献，而不是采用暴力评估。具体而言，我们发现从我们的体积光图中发射光线去替代这个估计值来作为环境光遮挡的光线会带来更合理的间接光结果。
我们还发现，与传统环境光遮蔽算法的可见度光线加权相比，所得到的辐照度光路更容易去噪。比较图像如图19-14所示。

 ![Figure 19-14][id]


#### 19.3.3.3 实时全局光照
除了使用预计算的光照贴图来渲染间接漫射光照外，我们还开发了一种路径追踪解决方案，进一步改善了我们的全局光照工作。在应用第19.3.3.4节中详述的重建滤波器之前，我们使用路径追踪和下一事件估计(next event estimation) 来渲染单反射间接漫射光，然后提供比以前更准确的颜色。   


#### 19.3.3.4 环境光遮蔽核漫反射全局光照的去噪
对于两个演示，我们使用了类似的降噪器，它基于Mehta et al.[9]提出的对于漫反射间接光照的轴对齐滤波器。 对于“光速”（保时捷）演示，去噪更具挑战性。由于我们在没有任何预计算的情况下使用蛮力路径追踪，我们结合了基于Mehta等人的空间滤波器和时间滤波器来实现期望的去噪效果。对于“反射”（Lucasfilm）演示，由于我们从邻近的光照贴图中取值，使用时域抗锯齿结合空间滤波器提供了足够好的质量。

我们仅将去噪器应用于光照的间接漫反射分量，以避免过度模糊纹理细节，阴影或镜面高光，因为这些在其他专用降噪器中单独滤波。对于空间滤波器，我们应用世界的空间域核，其具有由Mehta等人提出的命中距离导出的足迹(footprint)。使用命中距离调整滤镜大小可避免间接光照中的过度模糊细节，并使间接阴影等功能更加清晰。当与时间滤波器组合时，它还基于每个像素已累积的重投影样本的数量来减少空间域核占用。对于具有更多时域累积样本的像素，我们应用更小的空间滤波器足迹(footprint)，从而使结果更接近真实。

图19-15展示除了使用恒定半径进行滤波 和 基于光线命中距离和时间样本计数来调整滤波器半径的比较镜头。显然，使用自适应的滤波器足迹可以在接触区域提供更好的细节。

![Figure 19-15][id]

同样的思路也有助于光线追踪中环境光遮蔽的去噪。在图19-16中，我们比较（a）有恒定的世界空间半径的光线追踪环境光遮蔽的去噪效果 与（b）使用基于用命中距离和时域采样个数引导的自适应核半径去噪环境光遮挡的结果，
![Figure 19-16][id]

这再次明确表明使用自适应滤波器大小可以在环境光遮蔽的去噪中更好地保留接触细节。

### 19.3.4 RAY TRACED TRANSLUCENCY
 “光速”（保时捷）演示提出了许多新的挑战。团队最明显的初始挑战是渲染玻璃。用于渲染实时半透明的传统方法与延迟渲染算法冲突。通常，开发人员需要在单独的正向传递中渲染半透明几何体，并将结果复合到主延迟渲染上。可以应用于延迟渲染的技术通常不适用于半透明几何体，从而产生不兼容性，使得半透明和不透明几何体的集成变得困难。幸运的是，光线跟踪提供了表示半透明性的自然框架。通过光线跟踪，半透明几何体可以通过统一几何体提交的方式与延迟渲染轻松组合。它提供任意半透明的深度复杂性以及正确建模折射和吸收的能力。


### 19.3.4 光线追踪半透明效果
 “光速”（保时捷）演示中展现了许多新的挑战。 团队遭遇的最明显的初始挑战就是渲染玻璃。用于实时渲染半透明的传统方法同延迟渲染算法相冲突。通常，开发人员需要在单独的前向传递中渲染半透明几何体，并将结果复合到主要的延迟渲染上。可以应用于延迟渲染的技术通常不适用于半透明几何体，从而造成不兼容而使得半透明和不透明几何体的集成变得困难。

 幸运的是，光线追踪提供了表示半透明的一个自然的框架。通过光线追踪，半透明几何体可以通过统一几何体提交的方式与延迟渲染轻松组合。它提供任意半透明的深度复杂性以及正确建模折射和光强吸收的能力。


#### 19.3.4.1 光线生成
我们在虚幻引擎中实现光线追踪半透明使用了一个单独的光线追踪通路(pass)，类似于用于光线追踪反射的通路。实际上，大多数着色器代码在这两个通路(pass)之间共享。然而，两者之间的行为有一些细微差别。第一个是使用光线提前终止，以避免光线的吞吐量接近零之后不必要的场景遍历;即，如果光线传输地更远，其贡献可以忽略不计。另一个区别是半透明光线的路径长度有一个最大值可以避免继续撞击已经完全着色并存储在相应像素的不透明几何体。然而，如果执行折射，半透明命中可能会导致任意方向的新光线，并且此新光线或其后代可能会触及不透明几何体，这将需要进行着色计算。在我们对这种不透明命中执行任何照明之前，我们将不透明命中点重新投影到屏幕缓冲区，如果在此重投影步骤之后找到有效数据，则使用它们。这个简单的技巧使我们能够利用在G缓冲区中执行所有光线追踪照明和对不透明几何体进行去噪时获得的更高视觉质量。这可以用于一些有限量的折射，但是由于在这种情况下用错误的进入方向计算镜面光，结果可能是不正确的。


与反射通路的另一个关键差异是半透明光线在击中后续表面后递归地产生反射光线的能力。 使用HSLS来实现并不是简单的由于HSLS语言缺乏对递归的支持。这里的递归并不是指着能够在命中着色器后继续追踪光线，而是指能够使用简单的HLSL函数来调用自身。在HLSL中根本不允许这样做，但是实现Whitted样式的光线追踪算法时是期望这种做法的。为了解决HLSL的这种限制，我们将相同的代码实例化为具有不同名称的两个函数。我们有效地将相关的功能代码移动到一个单独的文件中，并将该文件引入两次，每次都设置函数名称的预处理器宏包围，从而使得具有不同名称的相同代码生成两个不同实例。然后我们用两个函数实例中的一个调用另一个，从而允许我们在一级硬编码限制下有效地进行的递归。 由此产生的实现允许半透明路径，具有可选的折射，沿路径的每次击中除了阴影光线之外还可以追踪“递归”反射光线。沿着该路径追踪半透明表面的反射可能会反弹到选定的次数。然而，如果在这些反弹中的任何一次半透明表面被击中，我们就不允许追踪额外的递归反射光线。
遵循比尔-朗伯定律(Beer-Lambert law)的均匀体积吸收(Homogeneous volumetric absorption)被添加到我们的半透明通路中以模拟厚玻璃并对基板(substrate)进行近似。为了正确地模拟均匀有界体积，对几何体施加了额外的约束。对光线遍历进行了修改，以明确地追踪前向和背面多边形，来克服交叉和非流形几何的问题。改进的视觉真实感由于性价比不高所以没有被包含在“光速”（保时捷）演示的最终版本中。

## 19.4 结论
最近推出的用于光线追踪加速的专用硬件以及在图形API中添加对于光线追踪的支持，促使我们进行创新并尝试一种新的、结合光栅化和​​光线追踪的混合渲染方式。我们在UE4（商业级游戏引擎）中完成了集成光线追踪的工程实践。我们发明了新颖的重建滤波器，用于渲染各种随机效果，比如光泽反射，软阴影，环境光遮蔽和漫反射间接光照，每个像素仅仅进行了一次光线采样，使这些昂贵的效果在现实生活中更加实用。我们已经成功地使用混合渲染来制作两个电影品质的演示短片。

## 致谢
作为一个历史记录，Epic Games与NVIDIA和ILMxLAB的合作，在2018年3月的游戏开发者大会上Epic的“State of Unreal”开幕会议期间首次公开展示了虚幻引擎中的实时光线追踪。该演示表现了使用虚幻引擎4构建的、来自The Force Awakens和The Last Jedi中的Star Warrs角色。它最初是通过微软的DirectX光线追踪API在NVIDIA的RTX技术上运行的。 
Mohen Leo（ILMxLAB）加入了Epic Games的Marcus Wassmer和Jerome Platteaux，负责开发和演示该演示中使用的技术。 ILMxLAB是Lucasfilm的沉浸式娱乐部门，以其在CARNE y ARENA，Star Wars：s: Secrets of the Empire, and the upcoming 
Vader Immortal: A Star Wars VR 系列中的工作而闻名。 许多其他曾为UE4的光线追踪内容和实施工作或咨询的人包括Guillaume Abadie，Francois Antoine，Louis Bavoil，Alexander Bogomjakov，Rob Bredow，Uriel Doyon，Maksim Eisenstein，Judah Graham，Evan Hart，Jon Hasselgren，Matthias Hollander，John Jack，Matthew Johnson，Brian Karis，Kim Libreri，Simone Lombardo，Adam Marrs，Gavin Moran，Jacob Munkberg，Yuriy O'Donnell，Min Oh，Jacopo Pantaleoni，Arne Schober，Jon Story，Peter Sumanaseni，Minjie Wu，Chris Wyman，and Micheal Zhang。
星球大战图像由Lucasfilm提供。





